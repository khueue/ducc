#!/usr/bin/env escript
%%! -pa ebin -Wall

usage() ->
    io:format('Usage: lexer~n'),
    io:format('(Uses stdin/stdout.)~n').

main([]) ->
    Stream = '<stdin>',
    Lines = tool_chain:read_lines_from_stream(standard_io),
    String = tool_chain:string_from_lines(Lines),
    {ok, Tokens} = try process(Stream, String)
    catch
        {tool_chain_exception, invalid_term} -> tool_chain:die(String);
        {_CompilationException, Message}     -> tool_chain:die(Message)
    end,
    Output = {{source,Lines}, {tokens,Tokens}},
    tool_chain:term_to_output(Output);
main(_) ->
    usage().

process(Stream, String) ->
    {ok, _Tokens} = lexer_driver:tokenize(Stream, String).
