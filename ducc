#!/usr/bin/env escript
%%! -pa ebin -Wall

version() ->
    '0.3.0'.

usage() ->
    io:fwrite('ducc ~s~n', [version()]),
    io:format('usage: ducc [-alptv] [file]~n').

main(["-v"]) ->
    io:fwrite('ducc ~s~n', [version()]);
main(["-l", File]) ->
    String = read_string(File),
    compile(lexer, File, String);
main(["-p", File]) ->
    String = read_string(File),
    compile(parser, File, String);
main(["-a", File]) ->
    String = read_string(File),
    compile(analyzer, File, String);
main(["-t", File]) ->
    String = read_string(File),
    compile(translator, File, String);
main([]) ->
    String = read_string(standard_io),
    compile(default, '<stdin>', String);
main([File]) ->
    String = read_string(File),
    compile(default, File, String);
main(_) ->
    usage().

read_string(standard_io) ->
    tool_chain:string_from_input();
read_string(Stream) ->
    Result = (catch tool_chain:string_from_file(Stream)),
    case Result of
        {ok, String} ->
            String;
        {file_exception, Message} ->
            tool_chain:die(Message)
    end.

compile(Program, Stream, String) ->
    Result = (catch process(Program, Stream, String)),
    case Result of
        {ok, ParseTree} ->
            tool_chain:term_to_output(ParseTree);
        {lexer_exception, Message} ->
            tool_chain:die(Message);
        {parser_exception, Message} ->
            tool_chain:die(Message);
        {analyzer_exception, Message} ->
            tool_chain:die(Message);
        {translator_exception, Message} ->
            tool_chain:die(Message);
        {tool_chain_exception, invalid_term} ->
            tool_chain:die(String);
        UnknownError ->
            tool_chain:die('~p~n', [UnknownError])
    end.

process(Program, Stream, String) ->
    case Program of
        lexer ->
            {ok, _Tokens} = lexer_driver:tokenize(Stream, String);
        parser ->
            {ok, Tokens} = lexer_driver:tokenize(Stream, String),
            {ok, _ParseTree} = parser_driver:parse(Stream, Tokens);
        analyzer ->
            {ok, Tokens} = lexer_driver:tokenize(Stream, String),
            {ok, ParseTree} = parser_driver:parse(Stream, Tokens),
            {ok, _ParseTree1} = analyzer_driver:analyze(Stream, ParseTree);
        translator ->
            {ok, Tokens} = lexer_driver:tokenize(Stream, String),
            {ok, ParseTree} = parser_driver:parse(Stream, Tokens),
            {ok, ParseTree1} = analyzer_driver:analyze(Stream, ParseTree),
            {ok, _ParseTree2} = translator_driver:translate(Stream, ParseTree1);
        _Default ->
            {ok, Tokens} = lexer_driver:tokenize(Stream, String),
            {ok, ParseTree} = parser_driver:parse(Stream, Tokens),
            {ok, ParseTree1} = analyzer_driver:analyze(Stream, ParseTree),
            {ok, _ParseTree2} = translator_driver:translate(Stream, ParseTree1)
    end.
